# Scenario 6 â€” PersonaPlex Voice Conversation Configuration
# Copy this file to .env and fill in the values.

# ==============================================================================
# REQUIRED: Hugging Face Token
# ==============================================================================
# Get your token at https://huggingface.co/settings/tokens
# You must also accept the model license at:
#   https://huggingface.co/nvidia/personaplex-7b-v1
HF_TOKEN=hf_your_token_here

# ==============================================================================
# OPTIONAL: Model Configuration
# ==============================================================================
# Local path to a pre-downloaded PersonaPlex model directory.
# If set, the app will load from this path instead of downloading from HuggingFace.
# Leave empty or commented out to auto-download from HuggingFace (default).
# PERSONAPLEX_MODEL_PATH=

# HuggingFace model cache directory. Defaults to ~/.cache/huggingface/hub
# HF_HOME=

# ==============================================================================
# OPTIONAL: Server Configuration
# ==============================================================================
# Port for the FastAPI web server (default: 8010)
# APP_PORT=8010

# Port for the PersonaPlex moshi backend server (default: 8998)
# MOSHI_PORT=8998

# Host to bind the web server to (default: 0.0.0.0)
# APP_HOST=0.0.0.0

# ==============================================================================
# OPTIONAL: Voice and Persona Configuration
# ==============================================================================
# Default voice prompt (e.g., NATF2, NATM1). See README for full list.
# DEFAULT_VOICE=NATF2

# Default text persona prompt
# DEFAULT_PERSONA=You are a wise and friendly teacher. Answer questions or provide advice in a clear and engaging way.

# ==============================================================================
# OPTIONAL: Performance
# ==============================================================================
# Enable CPU offloading if GPU memory is insufficient (true/false, default: false)
# CPU_OFFLOAD=false
